{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bit2ec1e9c1a2544dc9b47df98353f21a26",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# enable importing local modules from utils\n",
    "sys.path.insert(0, os.path.abspath('./utils'))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that elasticsearch is up and running (run `docker-compose up` before this if you haven't):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'count': 3,\n '_shards': {'total': 3, 'successful': 3, 'skipped': 0, 'failed': 0}}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "client = Elasticsearch()\n",
    "client.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that mongodb is up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'version': '4.2.2',\n 'gitVersion': 'a0bbbff6ada159e19298d37946ac8dc4b497eadf',\n 'modules': [],\n 'allocator': 'tcmalloc',\n 'javascriptEngine': 'mozjs',\n 'sysInfo': 'deprecated',\n 'versionArray': [4, 2, 2, 0],\n 'openssl': {'running': 'OpenSSL 1.1.1  11 Sep 2018',\n  'compiled': 'OpenSSL 1.1.1  11 Sep 2018'},\n 'buildEnvironment': {'distmod': 'ubuntu1804',\n  'distarch': 'x86_64',\n  'cc': '/opt/mongodbtoolchain/v3/bin/gcc: gcc (GCC) 8.2.0',\n  'ccflags': '-fno-omit-frame-pointer -fno-strict-aliasing -ggdb -pthread -Wall -Wsign-compare -Wno-unknown-pragmas -Winvalid-pch -Werror -O2 -Wno-unused-local-typedefs -Wno-unused-function -Wno-deprecated-declarations -Wno-unused-const-variable -Wno-unused-but-set-variable -Wno-missing-braces -fstack-protector-strong -fno-builtin-memcmp',\n  'cxx': '/opt/mongodbtoolchain/v3/bin/g++: g++ (GCC) 8.2.0',\n  'cxxflags': '-Woverloaded-virtual -Wno-maybe-uninitialized -fsized-deallocation -std=c++17',\n  'linkflags': '-pthread -Wl,-z,now -rdynamic -Wl,--fatal-warnings -fstack-protector-strong -fuse-ld=gold -Wl,--build-id -Wl,--hash-style=gnu -Wl,-z,noexecstack -Wl,--warn-execstack -Wl,-z,relro',\n  'target_arch': 'x86_64',\n  'target_os': 'linux'},\n 'bits': 64,\n 'debug': False,\n 'maxBsonObjectSize': 16777216,\n 'storageEngines': ['biggie', 'devnull', 'ephemeralForTest', 'wiredTiger'],\n 'ok': 1.0,\n '$clusterTime': {'clusterTime': Timestamp(1578829245, 1),\n  'signature': {'hash': b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00',\n   'keyId': 0}},\n 'operationTime': Timestamp(1578829245, 1)}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "client = pymongo.MongoClient()\n",
    "\n",
    "client.server_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch book files and prep data for mongo insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "https://www.gutenberg.org/files/1342/1342-0.txt\nhttps://www.gutenberg.org/files/11/11-0.txt\nhttps://www.gutenberg.org/ebooks/84.txt.utf-8\nParsed Pride and Prejudice by Jane Austen\nParsed Aliceâ€™s Adventures in Wonderland by Lewis Carroll\nParsed Frankenstein by Mary Wollstonecraft (Godwin) Shelley\nLength of parsed books: 3\n"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "URLS = pd.read_csv(os.path.join(\"data\", \"book_urls_small.csv\"))\n",
    "OUTPUT_PATH = os.path.join(\"data\", \"books\")\n",
    "\n",
    "\n",
    "def fetch_books(urls=URLS, output_path=OUTPUT_PATH):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    books = []\n",
    "\n",
    "    for url in URLS['url']:\n",
    "        print(url)\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        r.encoding = 'utf-8'\n",
    "        books.append(r.text.strip())\n",
    "\n",
    "    return books\n",
    "\n",
    "def parse_books(raw_books):\n",
    "    parsed_books = []\n",
    "\n",
    "    for raw_book in raw_books:\n",
    "        titleSearch = re.search(r\"^Title:\\s(.+)$\", raw_book, flags=re.MULTILINE)\n",
    "        authorSearch = re.search(r\"^Author:\\s(.+)$\", raw_book, flags=re.MULTILINE)\n",
    "\n",
    "        startOfBookSearch = re.search(r\"\\*\\*\\* START OF (THIS|THE) PROJECT GUTENBERG EBOOK .+ \\*\\*\\*\", raw_book)\n",
    "        endOfBookSearch = re.search(r\"\\*\\*\\* END OF (THIS|THE) PROJECT GUTENBERG EBOOK .+ \\*\\*\\*\", raw_book)\n",
    "\n",
    "        if titleSearch and authorSearch and startOfBookSearch and endOfBookSearch:\n",
    "            title = titleSearch.group(1).strip()\n",
    "            author = authorSearch.group(1).strip()\n",
    "            content = raw_book[startOfBookSearch.end():endOfBookSearch.start()]\n",
    "\n",
    "            print(\"Parsed \" + title + \" by \" + author)\n",
    "\n",
    "            parsed_books.append({ \n",
    "                'title': title, \n",
    "                'content': content, \n",
    "                'author': author })\n",
    "        else:\n",
    "            print(\"Failed to parse book\")\n",
    "\n",
    "    return parsed_books\n",
    "\n",
    "raw_books = fetch_books()\n",
    "parsed_books = parse_books(raw_books)\n",
    "\n",
    "print('Length of parsed books: ' + repr(len(parsed_books)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert books into our mongo `books` collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Inserted: 3\n"
    }
   ],
   "source": [
    "from pymongo import InsertOne\n",
    "\n",
    "def bulk_insert(books):\n",
    "    requests = []\n",
    "    for book in books:\n",
    "        requests.append(InsertOne(book))\n",
    "\n",
    "    result = books_collection.bulk_write(requests)\n",
    "\n",
    "    print(\"Inserted: \" + repr(result.inserted_count))\n",
    "\n",
    "bookworm_db = client['bookworm']\n",
    "books_collection = bookworm_db['books']\n",
    "\n",
    "bulk_insert(parsed_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}